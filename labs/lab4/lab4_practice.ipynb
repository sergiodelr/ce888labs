{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "df = pd.read_csv(\"jester-data-1.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "del df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings = df.values\n",
    "latent_user_preferences = None\n",
    "latent_item_features = None\n",
    "real_ratings_validation = []\n",
    "predictions = None\n",
    "def initialize(n_features):\n",
    "    global latent_user_preferences, latent_item_features, user_ratings, real_ratings_validation\n",
    "    \n",
    "    real_ratings_validation = [] #format: (i, j, rating)\n",
    "    #Remove data for validation set\n",
    "    for i in range(len(user_ratings)):\n",
    "        for j in range(len(user_ratings[0])):\n",
    "            if user_ratings[i][j] != 99 and random.random() <= 0.1:\n",
    "                real_ratings_validation.append((i, j, user_ratings[i][j]))\n",
    "                user_ratings[i][j] = 99\n",
    "\n",
    "    latent_user_preferences = np.random.random((user_ratings.shape[0], n_features))\n",
    "    latent_item_features = np.random.random((user_ratings.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(user_id,item_id):\n",
    "    \"\"\" Predict a rating given a user_id and an item_id.\n",
    "    \"\"\"\n",
    "    user_preference = latent_user_preferences[user_id]\n",
    "    item_preference = latent_item_features[item_id]\n",
    "    return user_preference.dot(item_preference)\n",
    "\n",
    "def train(user_id, item_id, rating,alpha):\n",
    "    \n",
    "    #print item_id\n",
    "    prediction_rating = predict_rating(user_id, item_id)\n",
    "    err =  ( prediction_rating- rating );\n",
    "    #print err\n",
    "    user_pref_values = latent_user_preferences[user_id][:]\n",
    "    latent_user_preferences[user_id] -= alpha * err * latent_item_features[item_id]\n",
    "    latent_item_features[item_id] -= alpha * err * user_pref_values\n",
    "    return err\n",
    "    \n",
    "\n",
    "\n",
    "def sgd(iterations = 30000, alpha = 0.0001):\n",
    "    \"\"\" Iterate over all users and all items and train for \n",
    "        a certain number of iterations\n",
    "    \"\"\"\n",
    "    mses = []\n",
    "    for iteration in range(0,iterations):\n",
    "        error = []\n",
    "        for user_id in range(0,latent_user_preferences.shape[0]):\n",
    "            for item_id in range(0,latent_item_features.shape[0]):\n",
    "                rating = user_ratings[user_id][item_id]\n",
    "                if rating != 99:\n",
    "                    err = train(user_id,item_id,rating, alpha)\n",
    "                    error.append(err)\n",
    "        mse = (np.array(error) ** 2).mean()   \n",
    "        if(iteration%10000 == 0 ):\n",
    "            mses.append(mse)\n",
    "            print(iteration)\n",
    "            print (mse)\n",
    "    return mses\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    global predictions, real_ratings_validation\n",
    "    errors = []\n",
    "    for v in real_ratings_validation:\n",
    "        i, j, r = v\n",
    "        errors.append(predictions[i][j] - r)\n",
    "    mse = (np.array(errors) ** 2).mean()\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resetUserRatings():\n",
    "    global real_ratings_validation, user_ratings\n",
    "    for v in real_ratings_validation:\n",
    "        i, j, r = v\n",
    "        user_ratings[i][j] = r \n",
    "    print(\"reset made\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init\n",
      "SGD\n",
      "0\n",
      "26.455041914191018\n"
     ]
    }
   ],
   "source": [
    "# Grid search\n",
    "alphas = [0.0001, 0.0007, 0.001, 0.007, 0.01, 0.07, 0.1]\n",
    "for n_features in range(2,7):\n",
    "    for a in alphas:\n",
    "        print(\"Init\")\n",
    "        initialize(n_features)\n",
    "        print(\"SGD\")\n",
    "        sgd(alpha=a)\n",
    "        print(\"predicting\")\n",
    "        predictions = lateng_user_preferences.dot(latent_item_features.T)\n",
    "        values = [zip(user_ratings[i], predictions[i]) for i in range(0,predictions.shape[0])]\n",
    "        resetUserRatings()\n",
    "        print(\"Parameters: alpha: %f, n_features: %d, validation error: %d\" % (a, n_features, validate()))\n",
    "        \n",
    "#comparison_data = pd.DataFrame(values)\n",
    "#comparison_data.columns = data.columns\n",
    "#comparison_data.applymap(lambda x,y: \"(%2.3f|%2.3f)\"%(x,y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
